# -*- coding: utf-8 -*-
"""Untitled36.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t0oANagNXjlZXNczcpBYDcmOoPpo4bQG
"""

pip install text2emotion

pip uninstall emoji

pip install emoji==1.7

import text2emotion as te

import nltk
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import csv
import seaborn as sns

!pip install transformers -q

from transformers import pipeline

"""# **Premchand-Story-1**"""

import csv
import re
import pandas as pd
def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/premchand-story-1.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []

df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file '{csv_filename}' is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file '{csv_filename}' is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Premchand-Story-2**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file '{csv_filename}' is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file '{csv_filename}' is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Premchand-Story-3**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file '{csv_filename}' is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file '{csv_filename}' is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Premchand-Story-4**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file '{csv_filename}' is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file '{csv_filename}' is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Premchand-Story-5**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []

df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file '{csv_filename}' is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file '{csv_filename}' is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/prem-chand-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rk-Narayan story -1**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/RkNarayan_s1.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-1-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-1-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/premchand-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rk-Narayan story -2**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rk-Narayan story -3**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rk-Narayan story -4**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rk-Narayan story -5**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rknarayan-story-5.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Ruskin-Bond-story-1**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Ruskin-Bond-story-2**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Ruskin-Bond-story-3**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Ruskin-Bond-story-4**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Ruskin-Bond-story-5**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("//content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("//content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("//content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("//content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("//content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("//content/drive/MyDrive/EmotionAnalysis/ruskin-bond-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Mulkraj-story-1**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-1_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Mulkraj-story-2**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-2-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Mulkraj-story-3**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Mulkraj-story-4**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Mulkraj-story-5**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/mulkraj-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rabindra-Nath-Story-1**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rabindra-Nath-Story-2**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()


# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-2_1-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rabindra-Nath-Story-3**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-3-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rabindra-Nath-Story-4**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4-pars.csv'

with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-4-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")

"""# **Rabindra-Nath-Story-5**"""

import csv
import re
import pandas as pd

def count_words(paragraph):
    return len(re.findall(r'\w+', paragraph))

input_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5.csv'
output_csv_file = '/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5-pars.csv'
with open(input_csv_file, 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

text_column = [row[0] for row in data]
paragraphs = []
current_paragraph = []

for text in text_column:
    if text.strip() == "":
        if len(current_paragraph) > 0:
            combined_paragraph = " ".join(current_paragraph)
            if 250 <= count_words(combined_paragraph):
                paragraphs.append(combined_paragraph)
            current_paragraph = []
    else:
        current_paragraph.append(text)

if len(current_paragraph) > 0:
    combined_paragraph = " ".join(current_paragraph)
    if 250 <= count_words(combined_paragraph):
        paragraphs.append(combined_paragraph)

results = []


df = pd.DataFrame(paragraphs, columns=None)
print(df)
df.to_csv(output_csv_file, index=False, header=False)

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline
import torch


# Load the tokenizer and model for fine-grained emotion analysis
tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')
model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')

# Load the emotion analysis pipeline
nlp = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Read the input CSV file without headers
input_df = pd.read_csv("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5-pars.csv", header=None)

# Get the paragraphs from the input DataFrame and filter out non-string items
paragraphs = [p for p in input_df[0].tolist() if isinstance(p, str)]

# Create a list to store the emotion analysis results for each paragraph
results = []

def truncate_text(text, max_chars):
    return text[:max_chars].rsplit(' ', 1)[0]

# Loop through each paragraph, perform emotion analysis, and store the results
for i, paragraph in enumerate(paragraphs):
    # Truncate the paragraph to a certain number of characters
    truncated_paragraph = truncate_text(paragraph, 400)

    # Perform emotion analysis and get emotion probabilities
    result = nlp(truncated_paragraph, return_all_scores=True)

    # Extract emotion probabilities
    emotion_probs = []
    for entry in result:
        for dicts in entry:
            emotion_probs.append((dicts['label'], round(dicts['score'], 3)))

    # Store the results as a dictionary
    results.append({
        "paragraph_num": i+1,
        "paragraph_text": paragraph,
        "emotion_probs": emotion_probs
    })


# Convert the results to a pandas DataFrame and save as a CSV file
df = pd.DataFrame(results)
df.to_csv("Premchand_Twitter_roberta.csv", index=False)


# Create a stacked bar chart to visualize the evolution of emotions
emotions = sorted(list(set([label for result in results for label, _ in result["emotion_probs"]])))

prob_matrix = np.zeros((len(results), len(emotions)))
for i, result in enumerate(results):
    for j, emotion in enumerate(emotions):
        for label, prob in result["emotion_probs"]:
            if label == emotion:
                prob_matrix[i, j] = prob
fig, ax = plt.subplots()
bar_width = 0.1
opacity = 0.8

index = np.arange(len(results))

for i, emotion in enumerate(emotions):
    ax.bar(index + i * bar_width, prob_matrix[:, i], bar_width, alpha=opacity, label=emotion)

ax.set_xticks(index + bar_width * (len(emotions) / 2))
ax.set_xticklabels([f"Para {i+1}" for i in range(len(results))])
ax.legend()
ax.set_ylabel("Probability")
ax.set_title("Evolution of Emotions")
plt.show()



# Create a DataFrame from the probability matrix and emotions
df = pd.DataFrame(prob_matrix, columns=emotions)

# Add a new column for Paragraph Number
df.insert(0, 'Paragraph', [f"Para {i+1}" for i in range(len(results))])

def color_column(data, color):
    """
    Returns color style for data according to the color provided
    """
    return ['background-color: %s' % color for v in data]

# Specify the colors for each column in a dictionary
column_colors = {'anger': 'blue', 'joy': 'orange', 'optimism': 'green', 'sadness': 'red'}  # replace with your column names and colors

# Apply color to each column
styled_df = df.style.apply(lambda data: color_column(data, column_colors[data.name] if data.name in column_colors else 'default'),
                           subset=pd.IndexSlice[:, list(column_colors.keys())])

styled_df

import csv

def count_words_in_csv(filename):
    word_count = 0
    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                words = cell.split()  # Split cell content into words
                word_count += len(words)
    return word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
num_words = count_words_in_csv(csv_filename)
print(f"The CSV file contains {num_words} words.")

import csv

def calculate_total_distinct_characters(filename):
    distinct_chars = set()

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars.update(cell)

    total_distinct_chars = len(distinct_chars)
    return total_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
total_chars = calculate_total_distinct_characters(csv_filename)
print(f"The total number of distinct characters in the CSV file is: {total_chars}")

import csv

def calculate_average_distinct_characters(filename):
    total_distinct_chars = 0
    total_cells = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            for cell in row:
                distinct_chars = set(cell)
                total_distinct_chars += len(distinct_chars)
                total_cells += 1

    if total_cells == 0:
        return 0  # To avoid division by zero error

    average_distinct_chars = total_distinct_chars / total_cells
    return average_distinct_chars

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_chars = calculate_average_distinct_characters(csv_filename)
print(f"The average count of distinct characters per cell in the CSV file is: {average_chars}")

import csv

def calculate_average_word_count_per_row(filename):
    total_word_count = 0
    total_rows = 0

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            words = row[0].split()  # Assuming the text is in the first column
            word_count = len(words)
            total_word_count += word_count
            total_rows += 1

    if total_rows == 0:
        return 0  # To avoid division by zero error

    average_word_count = total_word_count / total_rows
    return average_word_count

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_word_count = calculate_average_word_count_per_row(csv_filename)
print(f"The average word count per row in the CSV file is: {average_word_count}")

import csv

def calculate_average_row_length(filename):
    row_lengths = []

    with open("/content/drive/MyDrive/EmotionAnalysis/rabindra-story-5-pars.csv", 'r') as csv_file:
        csv_reader = csv.reader(csv_file)
        for row in csv_reader:
            row_length = sum(len(cell) for cell in row)
            row_lengths.append(row_length)

    if len(row_lengths) == 0:
        return 0  # To avoid division by zero error

    average_row_length = sum(row_lengths) / len(row_lengths)
    return average_row_length

# Usage example
csv_filename = 'example.csv'  # Replace with your CSV file path
average_row_length = calculate_average_row_length(csv_filename)
print(f"The average length of each row in the story is: {average_row_length} characters.")